{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Machine Learning Baselines\n",
        "\n",
        "This notebook demonstrates how to train and evaluate machine learning models for network anomaly detection.\n",
        "\n",
        "## Overview\n",
        "- Run data preprocessing pipeline\n",
        "- Train baseline ML models\n",
        "- Evaluate model performance\n",
        "- Visualize results with ROC curves and confusion matrices\n",
        "\n",
        "## Models\n",
        "We'll train and compare multiple ML algorithms including Random Forest, SVM, and XGBoost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import subprocess\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src to path for imports\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Preprocessing\n",
        "\n",
        "First, let's run the preprocessing pipeline to prepare our data for machine learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if processed data exists\n",
        "processed_data_path = Path(\"../data/processed/processed.csv\")\n",
        "\n",
        "if not processed_data_path.exists():\n",
        "    print(\"Processed data not found. Running preprocessing...\")\n",
        "    \n",
        "    # Run preprocessing script\n",
        "    try:\n",
        "        result = subprocess.run([\n",
        "            \"python\", \"../src/preprocess.py\",\n",
        "            \"--input\", \"../data/raw/sample.csv\",\n",
        "            \"--output\", \"../data/processed/processed.csv\"\n",
        "        ], capture_output=True, text=True, check=True)\n",
        "        \n",
        "        print(\"✅ Preprocessing completed successfully!\")\n",
        "        print(\"Output:\", result.stdout)\n",
        "        \n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"❌ Preprocessing failed:\")\n",
        "        print(\"Error:\", e.stderr)\n",
        "        print(\"Please run preprocessing manually:\")\n",
        "        print(\"python ../src/preprocess.py --input ../data/raw/sample.csv --output ../data/processed/processed.csv\")\n",
        "else:\n",
        "    print(\"✅ Processed data already exists!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data\n",
        "df = pd.read_csv(processed_data_path)\n",
        "print(f\"Loaded processed data: {df.shape}\")\n",
        "\n",
        "# Display basic info\n",
        "print(f\"Features: {df.shape[1] - 1}\")  # Excluding label column\n",
        "print(f\"Label distribution:\")\n",
        "print(df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train Machine Learning Models\n",
        "\n",
        "Now let's train our baseline ML models using the training script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ML models using the training script\n",
        "print(\"Training ML models...\")\n",
        "\n",
        "try:\n",
        "    result = subprocess.run([\n",
        "        \"python\", \"../src/train_ml.py\",\n",
        "        \"--data\", \"../data/processed/processed.csv\",\n",
        "        \"--out-model\", \"../models/ml_best.pkl\",\n",
        "        \"--mode\", \"quick\"\n",
        "    ], capture_output=True, text=True, check=True)\n",
        "    \n",
        "    print(\"✅ ML training completed successfully!\")\n",
        "    print(\"Training output:\")\n",
        "    print(result.stdout)\n",
        "    \n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"❌ ML training failed:\")\n",
        "    print(\"Error:\", e.stderr)\n",
        "    print(\"Please run training manually:\")\n",
        "    print(\"python ../src/train_ml.py --data ../data/processed/processed.csv --out-model ../models/ml_best.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load and Evaluate Trained Model\n",
        "\n",
        "Let's load the trained model and evaluate its performance on a test split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "model_path = Path(\"../models/ml_best.pkl\")\n",
        "\n",
        "if model_path.exists():\n",
        "    model = joblib.load(model_path)\n",
        "    print(f\"✅ Model loaded successfully!\")\n",
        "    print(f\"Model type: {type(model).__name__}\")\n",
        "    \n",
        "    # Load metadata if available\n",
        "    metadata_path = Path(\"../models/ml_best_metadata.joblib\")\n",
        "    if metadata_path.exists():\n",
        "        metadata = joblib.load(metadata_path)\n",
        "        print(f\"Model metadata: {metadata}\")\n",
        "else:\n",
        "    print(\"❌ Model file not found. Please train the model first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['label'])\n",
        "y = df['label']\n",
        "\n",
        "# Split data (same as training)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Test set class distribution:\")\n",
        "print(y_test.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessing components\n",
        "scaler_path = Path(\"../models/scaler.joblib\")\n",
        "label_encoder_path = Path(\"../models/label_encoder_label.joblib\")\n",
        "\n",
        "scaler = None\n",
        "label_encoder = None\n",
        "\n",
        "if scaler_path.exists():\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    print(\"✅ Scaler loaded\")\n",
        "    \n",
        "if label_encoder_path.exists():\n",
        "    label_encoder = joblib.load(label_encoder_path)\n",
        "    print(\"✅ Label encoder loaded\")\n",
        "\n",
        "# Apply preprocessing to test data\n",
        "if scaler is not None:\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "else:\n",
        "    X_test_scaled = X_test\n",
        "\n",
        "print(f\"Test data shape after scaling: {X_test_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "if model_path.exists():\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    # Prediction probabilities (if available)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_pred_proba = model.predict_proba(X_test_scaled)\n",
        "        y_pred_proba_positive = y_pred_proba[:, 1]  # Probability of positive class\n",
        "    else:\n",
        "        y_pred_proba_positive = y_pred  # Use predictions as probabilities\n",
        "    \n",
        "    print(\"✅ Predictions made successfully!\")\n",
        "    print(f\"Prediction shape: {y_pred.shape}\")\n",
        "else:\n",
        "    print(\"❌ Cannot make predictions - model not loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Evaluation and Visualization\n",
        "\n",
        "Let's evaluate the model performance and create visualizations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate evaluation metrics\n",
        "if model_path.exists():\n",
        "    # Classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "    \n",
        "    # ROC AUC score\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba_positive)\n",
        "        print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nROC AUC not available (model doesn't support predict_proba)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "if model_path.exists():\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=['Normal', 'Anomaly'], \n",
        "                yticklabels=['Normal', 'Anomaly'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ROC curve\n",
        "if model_path.exists() and hasattr(model, 'predict_proba'):\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba_positive)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"ROC curve not available - model doesn't support probability predictions\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Importance Analysis\n",
        "\n",
        "Let's examine which features are most important for the model's predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance (if available)\n",
        "if model_path.exists() and hasattr(model, 'feature_importances_'):\n",
        "    feature_importance = model.feature_importances_\n",
        "    feature_names = X.columns\n",
        "    \n",
        "    # Create feature importance DataFrame\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': feature_importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(\"Top 10 Most Important Features:\")\n",
        "    print(importance_df.head(10))\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    top_features = importance_df.head(15)\n",
        "    plt.barh(range(len(top_features)), top_features['importance'])\n",
        "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title('Top 15 Most Important Features')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "elif model_path.exists():\n",
        "    print(\"Feature importance not available for this model type\")\n",
        "else:\n",
        "    print(\"Model not loaded - cannot analyze feature importance\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary and Next Steps\n",
        "\n",
        "### Key Findings:\n",
        "1. **Model Performance**: [To be filled based on actual results]\n",
        "2. **Feature Importance**: [To be filled based on actual results]\n",
        "3. **ROC AUC Score**: [To be filled based on actual results]\n",
        "\n",
        "### Next Steps:\n",
        "1. **Hyperparameter Tuning**: Optimize model parameters for better performance\n",
        "2. **Ensemble Methods**: Try combining multiple models for improved accuracy\n",
        "3. **Feature Engineering**: Create new features based on domain knowledge\n",
        "4. **Deep Learning**: Explore neural network approaches\n",
        "5. **Cross-Validation**: Implement k-fold cross-validation for robust evaluation\n",
        "6. **Model Deployment**: Prepare the best model for production use\n",
        "7. **Real-time Monitoring**: Set up monitoring for model performance in production\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
